{# Set variables #}
{% set flink_version = '1.16.0' %}
{% set scala_version = '2.12' %}
{# Elastic Common Schema logging version.  Used for structured logging. #}
{% set ecs_version = '1.5.0' %}
{% set flink_mirror_base_uri = 'https://dlcdn.apache.org/flink' %}
{% set maven_mirror_base_uri = 'https://repo1.maven.org/maven2' %}
{# PGP Keyserver for verifying signatures of .jars downloaded from maven #}
{# Maven central uses keyserver.ubuntu.com. #}
{% set maven_keyserver = 'hkps://keyserver.ubuntu.com' %}
{% set flink_dist_dir = '/tmp/flink_dist' %}
{% set flink_install_dir = '/opt/flink' %}
{# End variables #}

# == Beginning of build stage ==

# NOTE: build stage does not consoladate RUN commands to take advantage
#       of more cached RUN layers. production image stage below DOES consolodate
#       RUN commands in order to have fewer layers there.

FROM {{ seed_image }} as build
USER root

RUN {{ "curl gpg gpg-agent dirmngr coreutils ca-certificates" | apt_install }}
WORKDIR /tmp


# TODO: reduce individual RUN steps to limit the number of layers we have to keep when building.

# Download flink distribution and sha512 checksum and GPG signature
# Then verify both checksum and signature before extracting the source.
RUN curl --remote-name-all "{{ flink_mirror_base_uri }}/flink-{{ flink_version }}/flink-{{ flink_version }}-bin-scala_{{ scala_version }}.tgz"
RUN curl --remote-name-all "{{ flink_mirror_base_uri }}/flink-{{ flink_version }}/flink-{{ flink_version }}-bin-scala_{{ scala_version }}.tgz.{asc,sha512}"
# Verify Flink distribution file checksum
RUN cat flink-{{ flink_version }}-bin-scala_{{ scala_version }}.tgz.sha512 flink-{{ flink_version }}-bin-scala_{{ scala_version }}.tgz | sha512sum --check --status
# Verify the Flink distribution file signature
RUN curl https://downloads.apache.org/flink/KEYS | gpg --import
RUN gpg --verify flink-{{ flink_version }}-bin-scala_{{ scala_version }}.tgz.asc flink-{{ flink_version }}-bin-scala_{{ scala_version }}.tgz
# Unpack the Flink distribution
RUN mkdir {{ flink_dist_dir }}
RUN tar xz -C {{ flink_dist_dir }} --strip-components=1 -f flink-{{ flink_version }}-bin-scala_{{ scala_version }}.tgz

# Copy any extra custom examples WMF adds into examples/wikimedia
# This pyflink datagen example runs forever, which makes it more useful for testing flink apps.
COPY --chown=root  examples/wikimedia {{ flink_dist_dir }}/examples/wikimedia

# Conditionally set GPG_HTTP_PROXY_OPTION if $http_proxy is set.
# gpg needs this set in --keyserver-options if an http proxy needs
# to be used when retrieving keys.
ENV GPG_HTTP_PROXY_OPTION=${http_proxy:+"http-proxy=${http_proxy}"}

# Download and verify ECS jars, and place them in the flink/lib directory.

# ecs-logging-core
RUN curl --remote-name-all "{{ maven_mirror_base_uri }}/co/elastic/logging/ecs-logging-core/{{ ecs_version }}/ecs-logging-core-{{ ecs_version }}.jar"
RUN curl --remote-name-all "{{ maven_mirror_base_uri }}/co/elastic/logging/ecs-logging-core/{{ ecs_version }}/ecs-logging-core-{{ ecs_version }}.jar.{asc,sha1}"
# Verify checksum
# NOTE: jar.sha1 file is not in expected sha sum format; it only has the sum.
# Echo the expected format into file.
RUN echo "$(cat ecs-logging-core-{{ ecs_version }}.jar.sha1)  ecs-logging-core-{{ ecs_version }}.jar" > ecs-logging-core-{{ ecs_version }}.jar.sha1
RUN sha1sum --check -c ecs-logging-core-{{ ecs_version }}.jar.sha1 --status
# Verify the signature
RUN gpg --auto-key-locate keyserver --keyserver {{ maven_keyserver }} --keyserver-options "auto-key-retrieve ${GPG_HTTP_PROXY_OPTION}" \
    --verify ecs-logging-core-{{ ecs_version }}.jar.asc ecs-logging-core-{{ ecs_version }}.jar
# mv jar into flink/lib
RUN mv ecs-logging-core-{{ ecs_version }}.jar {{ flink_dist_dir }}/lib/

# log4j-ecs-layout
RUN curl --remote-name-all "{{ maven_mirror_base_uri }}/co/elastic/logging/log4j2-ecs-layout/{{ ecs_version }}/log4j2-ecs-layout-{{ ecs_version }}.jar"
RUN curl --remote-name-all "{{ maven_mirror_base_uri }}/co/elastic/logging/log4j2-ecs-layout/{{ ecs_version }}/log4j2-ecs-layout-{{ ecs_version }}.jar.{asc,sha1}"
# Verify checksum
# NOTE: jar.sha1 file is not in expected sha sum format; it only has the sum.
# Echo the expected format into file.
RUN echo "$(cat log4j2-ecs-layout-{{ ecs_version }}.jar.sha1)  log4j2-ecs-layout-{{ ecs_version }}.jar" > log4j2-ecs-layout-{{ ecs_version }}.jar.sha1
RUN sha1sum --check -c log4j2-ecs-layout-{{ ecs_version }}.jar.sha1 --status
# Verify the signature
RUN gpg --auto-key-locate keyserver --keyserver pgp.mit.edu --keyserver-options "auto-key-retrieve ${GPG_HTTP_PROXY_OPTION}" \
    --verify log4j2-ecs-layout-{{ ecs_version }}.jar.asc log4j2-ecs-layout-{{ ecs_version }}.jar
# mv jar into flink/lib
RUN mv log4j2-ecs-layout-{{ ecs_version }}.jar {{ flink_dist_dir }}/lib/



# == End of build stage ==


# == Start of production image creation ==

FROM {{ "openjdk-11-jre" | image_tag }}

USER root

# Copy the base flink files from the binary distribution image into the target directory in this image
RUN mkdir -p {{ flink_install_dir }}/conf {{ flink_install_dir }}/plugins
COPY --from=build --chown=root {{ flink_dist_dir }}/lib {{ flink_install_dir }}/lib
COPY --from=build --chown=root {{ flink_dist_dir }}/bin {{ flink_install_dir }}/bin
COPY --from=build --chown=root {{ flink_dist_dir }}/opt {{ flink_install_dir }}/opt
# Examples are useful for testing this image without custom application code.
COPY --from=build --chown=root {{ flink_dist_dir }}/examples {{ flink_install_dir }}/examples
COPY --from=build --chown=root {{ flink_dist_dir }}/plugins/external-resource-gpu {{ flink_install_dir }}/plugins/external-resource-gpu
COPY --from=build --chown=root {{ flink_dist_dir }}/plugins/metrics-prometheus {{ flink_install_dir }}/plugins/metrics-prometheus
COPY --from=build --chown=root {{ flink_dist_dir }}/plugins/metrics-jmx {{ flink_install_dir }}/plugins/metrics-jmx
COPY --from=build --chown=root {{ flink_dist_dir }}/plugins/metrics-slf4j {{ flink_install_dir }}/plugins/metrics-slf4j
# TODO: kafka clients, flink-kafka, other connectors, etc.


# RUN:
# - Install debian packages.
#
# - Flink's default python interpreter is 'python', which in <= buster is python2.
#   We don't install python (2), so use update-alternatives to create a symlink to python3.
#   When openjdk-11-jre is upgraded to bullsye, we can use python-is-python3 .deb package.
#   This allows flink apps to not have to overridde -pyclientexec if they want to use the system python.
#
# - Remove flink scala deps -- we run scala free!
#   If you want to use scala in your Flink app, make it part of your application jar's included dependencies.
RUN {{ "bash krb5-user libnss3 procps net-tools libsnappy1v5 gettext-base libjemalloc-dev python3 wmf-certificates" | apt_install }} && \
    update-alternatives --install /usr/bin/python python /usr/bin/python3 10 && \
    rm -fv {{ flink_dist_dir }}/lib/flink-scala*

# ENV:
# - Add libjemalloc.so to LD_PRELOAD.
#   NOTE: Upstream flink-docker's docker-entrypoint.sh does this conditionally,
#   but we've explicitly installed libjemalloc-dev, so we can be sure this is
#   installed and can be enabled.
#
# - Set FLINK_HOME.
#
# - Include $FLINK_HOME/bin in PATH.  This is needed
#   because the kubernetes operator will attempt to run commands like
#   'kubernetes-jobmanager.sh kubernetes-application', and
#   'kubernetes-jobmanager.sh' is in Flink's bin/ directory.
#
ENV LD_PRELOAD=$LD_PRELOAD:/usr/lib/x86_64-linux-gnu/libjemalloc.so \
    FLINK_HOME={{ flink_install_dir }} \
    PATH={{ flink_install_dir }}/bin:$PATH

WORKDIR $FLINK_HOME

# Copy our custom entrypoint script to this image.
# Flink kubernetes native will run this by default.
# (This is overridable by setting kubernetes.entry.path in flink-conf.yaml
#  but the default is fine.  See comment in docker-entrypoint.sh for more info.)
COPY docker-entrypoint.sh /

RUN {{ "flink" | add_user }}
USER {{ "flink" | uid }}

# NOTE: flink native kubernetes will always run this image with a command constructed using the
# 'kubernetes.entry.path' config, which defaults to /docker-entrypoint.sh.
# We set it here anyway to avoid confusion.
ENTRYPOINT ["/docker-entrypoint.sh"]

# == End of image creation ==
