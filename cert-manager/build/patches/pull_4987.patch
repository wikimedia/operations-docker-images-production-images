From 63e3b7a0a87ebf2a646d48589aad1a48c51e226e Mon Sep 17 00:00:00 2001
From: jayme-github <jayme-github@users.noreply.github.com>
Date: Fri, 25 Mar 2022 15:02:11 +0100
Subject: [PATCH] Add controller_sync_error_count metric

Introducing a new metric controller_sync_error_count counting the
number of errors during sync() of a controller.

This adds more visibility to potential issues ranging from things like
connection problems to the API or webhooks to possible hard errors.

For context, please see #4956

Signed-off-by: Janis Meybohm <jmeybohm@wikimedia.org>
---
 pkg/controller/controller.go |  4 ++++
 pkg/metrics/metrics.go       | 17 +++++++++++++++++
 2 files changed, 21 insertions(+)

diff --git a/pkg/controller/controller.go b/pkg/controller/controller.go
index 0309430606..a040e9d64a 100644
--- a/pkg/controller/controller.go
+++ b/pkg/controller/controller.go
@@ -159,8 +159,12 @@ func (c *controller) worker(ctx context.Context) {
 			if err != nil {
 				if strings.Contains(err.Error(), genericregistry.OptimisticLockErrorMsg) {
 					log.Info("re-queuing item due to optimistic locking on resource", "error", err.Error())
+					// These errors are not counted towards the controllerSyncErrorCount metric on purpose
+					// as they will go way with
+					// https://github.com/cert-manager/cert-manager/blob/master/design/20220118.server-side-apply.md
 				} else {
 					log.Error(err, "re-queuing item due to error processing")
+					c.metrics.IncrementSyncErrorCount(c.name)
 				}
 
 				c.queue.AddRateLimited(obj)
diff --git a/pkg/metrics/metrics.go b/pkg/metrics/metrics.go
index 9baba13c25..8480fae8a4 100644
--- a/pkg/metrics/metrics.go
+++ b/pkg/metrics/metrics.go
@@ -59,6 +59,7 @@ type Metrics struct {
 	acmeClientRequestDurationSeconds *prometheus.SummaryVec
 	acmeClientRequestCount           *prometheus.CounterVec
 	controllerSyncCallCount          *prometheus.CounterVec
+	controllerSyncErrorCount         *prometheus.CounterVec
 }
 
 var readyConditionStatuses = [...]cmmeta.ConditionStatus{cmmeta.ConditionTrue, cmmeta.ConditionFalse, cmmeta.ConditionUnknown}
@@ -157,6 +158,15 @@ func New(log logr.Logger, c clock.Clock) *Metrics {
 			},
 			[]string{"controller"},
 		)
+
+		controllerSyncErrorCount = prometheus.NewCounterVec(
+			prometheus.CounterOpts{
+				Namespace: namespace,
+				Name:      "controller_sync_error_count",
+				Help:      "The number of errors encountered during controller sync().",
+			},
+			[]string{"controller"},
+		)
 	)
 
 	// Create server and register Prometheus metrics handler
@@ -172,6 +182,7 @@ func New(log logr.Logger, c clock.Clock) *Metrics {
 		acmeClientRequestCount:           acmeClientRequestCount,
 		acmeClientRequestDurationSeconds: acmeClientRequestDurationSeconds,
 		controllerSyncCallCount:          controllerSyncCallCount,
+		controllerSyncErrorCount:         controllerSyncErrorCount,
 	}
 
 	return m
@@ -187,6 +198,7 @@ func (m *Metrics) NewServer(ln net.Listener) *http.Server {
 	m.registry.MustRegister(m.acmeClientRequestDurationSeconds)
 	m.registry.MustRegister(m.acmeClientRequestCount)
 	m.registry.MustRegister(m.controllerSyncCallCount)
+	m.registry.MustRegister(m.controllerSyncErrorCount)
 
 	mux := http.NewServeMux()
 	mux.Handle("/metrics", promhttp.HandlerFor(m.registry, promhttp.HandlerOpts{}))
@@ -206,3 +218,8 @@ func (m *Metrics) NewServer(ln net.Listener) *http.Server {
 func (m *Metrics) IncrementSyncCallCount(controllerName string) {
 	m.controllerSyncCallCount.WithLabelValues(controllerName).Inc()
 }
+
+// IncrementSyncErrorCount will increase count of errors during sync of that controller.
+func (m *Metrics) IncrementSyncErrorCount(controllerName string) {
+	m.controllerSyncErrorCount.WithLabelValues(controllerName).Inc()
+}
